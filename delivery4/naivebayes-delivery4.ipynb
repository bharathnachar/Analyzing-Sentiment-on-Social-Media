{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "forty-welding",
   "metadata": {},
   "source": [
    "# ISE Data Science - Delivery #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-senate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-vitamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data\n",
    "df = pd.read_csv('F:\\\\downloads\\\\training.1600000.processed.noemoticon.csv', header=None, encoding='latin')\n",
    "df.columns = ['label', 'id', 'date', 'query', 'user', 'tweet']\n",
    "\n",
    "# Data reduction\n",
    "df = df.drop(['id', 'date', 'query', 'user'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-costa",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {0:'Negative', 2:'Neutral', 4:'Positive'}\n",
    "\n",
    "def convert_labels(label):\n",
    "    return labels_dict[label]\n",
    "\n",
    "df.label = df.label.apply(lambda x: convert_labels(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-enforcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = df.label.value_counts()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar(instances.index, instances.values)\n",
    "plt.title(\"Data Distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-diagnosis",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-quantity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "punctuations_and_dummies = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "def preprocess(df, will_be_stemmed=False):\n",
    "    for index, row in df.iterrows():\n",
    "        tweet = row.tweet\n",
    "        tweet = re.sub(punctuations_and_dummies, ' ', str(tweet).lower()).strip()\n",
    "        tokens = []\n",
    "        for token in tweet.split():\n",
    "            if token not in stop_words:\n",
    "                if will_be_stemmed:\n",
    "                    tokens.append(stemmer.stem(token))\n",
    "                else:\n",
    "                    tokens.append(token)\n",
    "        df.tweet = \" \".join(tokens)\n",
    "\n",
    "\n",
    "preprocess(df.tweet)\n",
    "'''\n",
    "\n",
    "\n",
    "def preprocess(tweet, will_be_stemmed=False):\n",
    "        tweet = re.sub(punctuations_and_dummies, ' ', str(tweet).lower()).strip()\n",
    "        tokens = []\n",
    "        for token in tweet.split():\n",
    "            if token not in stop_words:\n",
    "                if will_be_stemmed:\n",
    "                    tokens.append(stemmer.stem(token))\n",
    "                else:\n",
    "                    tokens.append(token)\n",
    "        return \" \".join(tokens)\n",
    "    \n",
    "df.tweet = df.tweet.apply(lambda tw: preprocess(tw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 0 length tweets\n",
    "df = df[df.iloc[:,1].astype(str).str.len()!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-advancement",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_len = [len(x) for x in df['tweet']]\n",
    "pd.Series(tweets_len).hist()\n",
    "plt.show()\n",
    "pd.Series(tweets_len).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-demographic",
   "metadata": {},
   "source": [
    "### Number of Letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-million",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_str = \"\"\n",
    "for i in df.tweet:\n",
    "    all_str += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-cheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "letter_list = list(all_str)\n",
    "my_counter = Counter(letter_list)\n",
    "\n",
    "letter_df = pd.DataFrame.from_dict(my_counter, orient='index').reset_index()\n",
    "letter_df = letter_df.rename(columns={'index':'letter', 0:'frequency'})\n",
    "letter_df = letter_df.loc[letter_df['letter'].isin(['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z'])]\n",
    "letter_df['all_tweets_relative_freq']=letter_df['frequency']/letter_df['frequency'].sum()\n",
    "letter_df = letter_df.sort_values('letter')\n",
    "\n",
    "english = pd.read_csv('../data/letter_frequency_en_US.csv')\n",
    "english['expected_relative_frequency'] = english['count']/english['count'].sum()\n",
    "english = english.drop(['count'], axis=1)\n",
    "\n",
    "letter_df = pd.merge(letter_df, english, on='letter')\n",
    "letter_df['expected'] = np.round(letter_df['expected_relative_frequency']*letter_df['frequency'].sum(),0)\n",
    "letter_df = letter_df.reset_index().drop(['index'], axis=1)\n",
    "letter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-weather",
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_df.plot(x=\"letter\", y=[\"all_tweets_relative_freq\", \"expected_relative_frequency\"], kind=\"barh\", figsize=(12,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-philadelphia",
   "metadata": {},
   "source": [
    "#### Compare the Observed Frequencies with the Expected Frequencies in English "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-invite",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "# Chi-square test of independence.\n",
    "c, p, dof, expected = chi2_contingency(letter_df[['frequency', 'expected']])\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-theta",
   "metadata": {},
   "source": [
    "We get that the p-value (p) is 0 which implies that the letter frequency does not follow the same distribution with what we see in English tests, although the Pearson correlation is too high (~96.7%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-discretion",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "letter_df[['frequency', 'expected']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-verse",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "\n",
    "df1['number_of_characters'] = [len(tw) for tw in df1.tweet]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-blackberry",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.number_of_characters.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-closing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.number_of_characters.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-holocaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.number_of_characters.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.number_of_characters.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-inspector",
   "metadata": {},
   "source": [
    "## Number of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-emperor",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['number_of_words'] = [len(tw.split()) for tw in df1.tweet]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-damage",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.number_of_words.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-pacific",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.number_of_words.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.number_of_words.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.number_of_words.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-matthew",
   "metadata": {},
   "source": [
    "### Positives + Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-gentleman",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "from wordcloud import WordCloud\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.util import ngrams\n",
    "\n",
    "all_tweets = ' '.join(df['tweet'].str.lower())\n",
    "\n",
    "f_words = [word for word in all_tweets.split()]\n",
    "counted_words = collections.Counter(f_words)\n",
    "\n",
    "words = []\n",
    "counts = []\n",
    "for letter, count in counted_words.most_common(20):\n",
    "    words.append(letter)\n",
    "    counts.append(count)\n",
    "    \n",
    "plt.figure(figsize = (16, 4))\n",
    "plt.title('Most common words in whole tweets')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Words')\n",
    "plt.bar(words, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-parks",
   "metadata": {},
   "source": [
    "### Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-peninsula",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_tweets = ' '.join(df[df.label == 'Positive'].tweet.str.lower())\n",
    "\n",
    "f_words = [word for word in all_tweets.split()]\n",
    "counted_words = collections.Counter(f_words)\n",
    "\n",
    "words = []\n",
    "counts = []\n",
    "for letter, count in counted_words.most_common(20):\n",
    "    words.append(letter)\n",
    "    counts.append(count)\n",
    "    \n",
    "plt.figure(figsize = (16, 4))\n",
    "plt.title('Most common words in positive tweets')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Words')\n",
    "plt.bar(words, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25, 25))\n",
    "plt.axis('off')\n",
    "wordcloud_fig = WordCloud(max_words = 2000 , width = 1600 , height = 800, background_color ='white', min_font_size = 10).generate(\" \".join(df[df.label == 'Positive'].tweet))\n",
    "plt.imshow(wordcloud_fig, interpolation = 'bilinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-discipline",
   "metadata": {},
   "source": [
    "### Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-crash",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets = ' '.join(df[df.label == 'Negative'].tweet.str.lower())\n",
    "\n",
    "f_words = [word for word in all_tweets.split()]\n",
    "counted_words = collections.Counter(f_words)\n",
    "\n",
    "words = []\n",
    "counts = []\n",
    "for letter, count in counted_words.most_common(20):\n",
    "    words.append(letter)\n",
    "    counts.append(count)\n",
    "    \n",
    "plt.figure(figsize = (16, 4))\n",
    "plt.title('Most common words in negative tweets')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Words')\n",
    "plt.bar(words, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-kingdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "plt.figure(figsize = (25, 25))\n",
    "plt.axis('off')\n",
    "wordcloud_fig = WordCloud(max_words = 2000 , width = 1600 , height = 800, background_color ='white', min_font_size = 10).generate(\" \".join(df[df.label == 'Negative'].tweet))\n",
    "plt.imshow(wordcloud_fig, interpolation = 'bilinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-bundle",
   "metadata": {},
   "source": [
    "### Training Data and Test Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-explanation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=7)\n",
    "print('Training Data', len(train_data), 'Test Data', len(test_data))\n",
    "\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-violation",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-success",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-settle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_data.tweet)\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Vocabulary Size :\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-sussex",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train = pad_sequences(tokenizer.texts_to_sequences(train_data.tweet), maxlen = 30)\n",
    "X_test = pad_sequences(tokenizer.texts_to_sequences(test_data.tweet), maxlen = 30)\n",
    "\n",
    "print(\"X_train, X_test\", X_train.shape, X_test.shape)\n",
    "\n",
    "labels = train_data.label.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_data.label.to_list())\n",
    "\n",
    "y_train = encoder.transform(train_data.label.to_list())\n",
    "y_test = encoder.transform(test_data.label.to_list())\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-improvement",
   "metadata": {},
   "source": [
    "### GLOVE Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-medicare",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_PATH = '../models'\n",
    "EMBEDDING_DIMENSION = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-german",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "EPOCHS = 10\n",
    "LR = 1e-3\n",
    "\n",
    "embeddings_index = {}\n",
    "\n",
    "glove_file = open('../glove/glove.6B.300d.txt', encoding='utf8')\n",
    "for line in glove_file:\n",
    "    values = line.split()\n",
    "    word = value = values[0]\n",
    "    coefficients = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefficients\n",
    "glove_file.close()\n",
    "\n",
    "print('%s word vectors.' % len(embeddings_index))\n",
    "\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIMENSION))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "embedding_layer = tf.keras.layers.Embedding(vocab_size, EMBEDDING_DIMENSION, weights=[embedding_matrix], input_length=30, trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-summary",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-gnome",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#K = 20000\n",
    "#shuffled_df = df.sample(frac=1).reset_index(drop=True)\n",
    "first_K_tweets = train_data['tweet']\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "vec = vectorizer.fit(first_K_tweets)\n",
    "\n",
    "vec = vectorizer.transform(first_K_tweets)\n",
    "\n",
    "# Dictionary\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-mouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST Tweets\n",
    "\n",
    "test_vec = vectorizer.transform(test_data['tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-thumb",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-master",
   "metadata": {},
   "source": [
    "### Naive Bayes - CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(vec, train_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-retrieval",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = classifier.predict(test_vec)\n",
    "score = (classifier.score(test_vec, test_data['label'])) * 100\n",
    "print('CountVectorizer Naive Bayes score= '+ str(score) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "cf_matrix = confusion_matrix(test_data['label'], y_prediction)\n",
    "print(cf_matrix)\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "labels = ['True Neg','False Pos','False Neg','True Pos']\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-lewis",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_data['label'], y_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-weight",
   "metadata": {},
   "source": [
    "## Naive Bayes - TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-trainer",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-chambers",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Learn vocabulary from tweets \n",
    "tfidf_vec = tfidf_vectorizer.fit(first_K_tweets)\n",
    "\n",
    "# Vocabulary\n",
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-transformation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to document by term matrix\n",
    "tfidf_vec = tfidf_vectorizer.transform(first_K_tweets)\n",
    "#tfidf_vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-struggle",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test_vec = tfidf_vectorizer.transform(test_data['tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-ready",
   "metadata": {},
   "source": [
    "### Training - NaiveBayes TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-mason",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_classifier = MultinomialNB()\n",
    "tfidf_classifier.fit(tfidf_vec, train_data['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-oregon",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = tfidf_classifier.predict(tfidf_test_vec)\n",
    "score = (tfidf_classifier.score(tfidf_test_vec, test_data['label'])) * 100\n",
    "print(\"tf-idf NÃ¤ive_Bayes score = \" + str(score) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-craft",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "cf_matrix = confusion_matrix(test_data['label'], y_prediction)\n",
    "print(cf_matrix)\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "labels = ['True Neg','False Pos','False Neg','True Pos']\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt='', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-presentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_data['label'], y_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-investigation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
